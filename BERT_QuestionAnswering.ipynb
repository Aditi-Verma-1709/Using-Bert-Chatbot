{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering with a pretrained BERT model (Finetuned for QA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#Huggingface'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (1.9)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\anaconda3\\lib\\site-packages (from torch) (2.6.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers #Huggingface\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch #pytorch\n",
    "from transformers import BertForQuestionAnswering, AutoModelForQuestionAnswering\n",
    "from transformers import BertTokenizer, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question  = \"Where did the FIFA world cup 2022 happen ?\"\n",
    "text = \"The 2022 FIFA World Cup was the 22nd FIFA World Cup, the quadrennial world championship for national football teams organized by FIFA. It took place in Qatar from 20 November to 18 December 2022, after the country was awarded the hosting rights in 2010.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(question, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{101: '[CLS]',\n",
       " 2073: 'where',\n",
       " 2106: 'did',\n",
       " 1996: 'the',\n",
       " 5713: 'fifa',\n",
       " 2088: 'world',\n",
       " 2452: 'cup',\n",
       " 16798: '202',\n",
       " 2475: '##2',\n",
       " 4148: 'happen',\n",
       " 1029: '?',\n",
       " 102: '[SEP]',\n",
       " 2001: 'was',\n",
       " 13816: '22nd',\n",
       " 1010: ',',\n",
       " 17718: 'quad',\n",
       " 7389: '##ren',\n",
       " 6200: '##nia',\n",
       " 2140: '##l',\n",
       " 2528: 'championship',\n",
       " 2005: 'for',\n",
       " 2120: 'national',\n",
       " 2374: 'football',\n",
       " 2780: 'teams',\n",
       " 4114: 'organized',\n",
       " 2011: 'by',\n",
       " 1012: '.',\n",
       " 2009: 'it',\n",
       " 2165: 'took',\n",
       " 2173: 'place',\n",
       " 1999: 'in',\n",
       " 12577: 'qatar',\n",
       " 2013: 'from',\n",
       " 2322: '20',\n",
       " 2281: 'november',\n",
       " 2000: 'to',\n",
       " 2324: '18',\n",
       " 2285: 'december',\n",
       " 2044: 'after',\n",
       " 2406: 'country',\n",
       " 3018: 'awarded',\n",
       " 9936: 'hosting',\n",
       " 2916: 'rights',\n",
       " 2230: '2010'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(input_ids, tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sep_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input 1 = Question\n",
    "Input 2 = Passage/Text\n",
    "Output 1 = Answer\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def question_answer(question, text):\n",
    "    \n",
    "    #tokenize question and text in ids as a pair\n",
    "    input_ids = tokenizer.encode(question, text)\n",
    "    \n",
    "    #string version of tokenized ids\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    \n",
    "    #segment IDs\n",
    "    #first occurence of [SEP] token\n",
    "    sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "    #number of tokens in segment A - question\n",
    "    num_seg_a = sep_idx+1\n",
    "\n",
    "    #number of tokens in segment B - text\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "    \n",
    "    #list of 0s and 1s\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "    \n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "    \n",
    "    #model output using input_ids and segment_ids\n",
    "    output = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
    "    \n",
    "    #reconstructing the answer\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "\n",
    "    if answer_end >= answer_start:\n",
    "        answer = tokens[answer_start]\n",
    "        for i in range(answer_start+1, answer_end+1):\n",
    "            if tokens[i][0:2] == \"##\":\n",
    "                answer += tokens[i][2:]\n",
    "            else:\n",
    "                answer += \" \" + tokens[i]\n",
    "                \n",
    "    if answer.startswith(\"[CLS]\"):\n",
    "        answer = \"Unable to find the answer to your question.\"\n",
    "    \n",
    "#     print(\"Text:\\n{}\".format(text.capitalize()))\n",
    "#     print(\"\\nQuestion:\\n{}\".format(question.capitalize()))\n",
    "    print(\"\\nAnswer:\\n{}\".format(answer.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "The 2022 fifa world cup was the 22nd fifa world cup\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"The 2022 FIFA World Cup was the 22nd FIFA World Cup, the quadrennial world championship for national football teams organized by FIFA. It took place in Qatar from 20 November to 18 December 2022, after the country was awarded the hosting rights in 2010\"\"\"\n",
    "\n",
    "question = \"Was the FIFA World cup Quadrennial world championship ?\"\n",
    "\n",
    "question_answer(question, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing with the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your text: \n",
      "My name is Aditi Verma. I have completed my Masters in Applied Mathematics in 2023.\n",
      "\n",
      "Please enter your question: \n",
      "Whne did Aditi complete her Masters?\n",
      "\n",
      "Answer:\n",
      "Applied mathematics\n",
      "\n",
      "Do you want to ask another question based on this text (Y/N)? Y\n",
      "\n",
      "Please enter your question: \n",
      "In which year did Aditi Completed MSc Applied mathematics?\n",
      "\n",
      "Answer:\n",
      "2023\n",
      "\n",
      "Do you want to ask another question based on this text (Y/N)? What is the name?\n",
      "\n",
      "Do you want to ask another question based on this text (Y/N)? Y\n",
      "\n",
      "Please enter your question: \n",
      "What is her name?\n",
      "\n",
      "Answer:\n",
      "Aditi verma\n",
      "\n",
      "Do you want to ask another question based on this text (Y/N)? Y\n",
      "\n",
      "Please enter your question: \n",
      "Has she done her Masters?\n",
      "\n",
      "Answer:\n",
      "I have completed my masters in applied mathematics in 2023\n",
      "\n",
      "Do you want to ask another question based on this text (Y/N)? N\n",
      "\n",
      "Bye!\n"
     ]
    }
   ],
   "source": [
    "text = input(\"Please enter your text: \\n\")\n",
    "question = input(\"\\nPlease enter your question: \\n\")\n",
    "\n",
    "while True:\n",
    "    question_answer(question, text)\n",
    "    \n",
    "    flag = True\n",
    "    flag_N = False\n",
    "    \n",
    "    while flag:\n",
    "        response = input(\"\\nDo you want to ask another question based on this text (Y/N)? \")\n",
    "        if response[0] == \"Y\":\n",
    "            question = input(\"\\nPlease enter your question: \\n\")\n",
    "            flag = False\n",
    "        elif response[0] == \"N\":\n",
    "            print(\"\\nBye!\")\n",
    "            flag = False\n",
    "            flag_N = True\n",
    "            \n",
    "    if flag_N == True:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "336109dad5676e38bf25ab56de492449c5617d71daf49644f2b376d0220af732"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
